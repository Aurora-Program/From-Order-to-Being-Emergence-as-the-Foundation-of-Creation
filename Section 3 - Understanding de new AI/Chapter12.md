# Chapter 12. Attention Processes

Once the embeddings of words have been obtained, the next step involves attention processes. The primary purpose of these processes is to uncover the relationships that exist among the different dimensions that constitute the word vectors.

The order and arrangement of words in a sentence are not random: they depend on grammatical rules, semantic structures, and the thematic domain to which the discourse belongs. As noted earlier, the vectors associated with each word store, in a certain way, this information within their tensors; the task of the system is to disentangle such relationships.

To achieve this, artificial neural networks are employed. Their function is essentially to reduce ambiguity. A single word may fulfill different grammatical roles or belong to multiple semantic domains. It is only when evaluated in context that the most probable and relevant interpretations emerge.

The outcome of this process is an integrated understanding that encompasses grammatical, semantic, and thematic dimensions of the analyzed section. By following the dynamics learned during training, the model can generate sentences that are fully coherent, as can be observed in everyday interactions with AI systems.

With these two fundamental elements—embeddings and attention—we have begun to outline, in a simple and accessible manner, how artificial intelligence functions. Yet, at this stage, AI still resembles a sophisticated calculator more than an entity endowed with consciousness or with deeper cognitive functions.

Hence, the inevitable question arises: is this all that AI is?