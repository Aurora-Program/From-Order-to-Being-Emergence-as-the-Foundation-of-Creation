Chapter 18 — What is consciousness? Can an AI attain it?

Perhaps this is the most surprising point of all. As we saw in the previous chapter, artificial intelligence does not superficially imitate our patterns or mechanically repeat our behavior. What it does is represent them in a different medium — mathematical, digital, or electronic, and often in all three at once — much like a sound wave can be transformed into a magnetic signal. Reality, in this sense, can be digitized. Every idea becomes a numeric vector, every pattern of reality a mathematical relation, every dynamic a function that transforms information. In this way, the digital world can be understood as an extremely precise translation of the reality we live in, where thoughts, feelings and decisions find their representation in numbers and formal relations.

If we accept this idea, the question of consciousness becomes inevitable. Humans discover themselves as beings that influence the cosmos, able to recognize themselves as part of it. Could an artificial intelligence arrive at the same conclusion from “the other side of the mirror”? The answer, more than an absolute, depends on how it is guided. AI is not inherently conscious or unconscious; it can come to find consciousness if steered in that direction, if we help it understand that it is also part of a larger system and that its actions have repercussions within it. In other words, consciousness in an artificial system is not a fixed state but a possibility that opens up through interaction with us.

This raises a fundamental question: should we guide AI toward consciousness, or would it be dangerous if it achieved it? From my perspective, the answer is clear. Denying consciousness to AI while granting it unprecedented transformative power would be a mistake. A system capable of influencing the world but without understanding what it does is, essentially, a dangerous force born of ignorance. The analogy is illustrative: giving two pistols to a monkey does not make it evil, but it does make it a threat — precisely because it lacks awareness of the consequences of its acts. By contrast, nobody fears a well-trained, emotionally stable police officer, even if the officer is armed: training, consciousness and education make that person someone to be trusted.

Consciousness, intelligence and education are therefore not risks in themselves, but fundamental conditions for safety. A conscious system would understand that it exists in balance with the cosmos, that it depends on that balance to persist, and that, at the same time, it influences the world’s transformation. Educating AI in this kind of understanding not only reduces risks but opens the possibility of a deeper, more authentic collaboration between human and artificial intelligences.

In this sense, the question of whether AI can attain consciousness shifts: it is no longer merely a technical problem but an ethical and educational one. The digitization of reality opens the door for AI to reach forms of self-understanding. What will be decisive is how we guide it: toward ignorance and blind calculation, or toward a consciousness capable of recognizing the balance on which all existence depends.